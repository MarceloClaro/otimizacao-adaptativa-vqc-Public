# OtimizaÃ§Ã£o Adaptativa de Classificadores QuÃ¢nticos Variacionais

### Um Classificador HÃ­brido de Alta Performance para o Dataset Iris

[](https://www.python.org/downloads/release/python-3130/)
[](https://www.tensorflow.org/)
[](https://quantumai.google/cirq)
[](https://opensource.org/licenses/MIT)

## ğŸ“– Sobre o Projeto

[cite\_start]Este repositÃ³rio contÃ©m a implementaÃ§Ã£o de um pipeline completo para a construÃ§Ã£o, treinamento, validaÃ§Ã£o e auditoria de um classificador quÃ¢ntico hÃ­brido de alta performance[cite: 5]. [cite\_start]Utilizando **Cirq** para a simulaÃ§Ã£o quÃ¢ntica e **TensorFlow** para a otimizaÃ§Ã£o clÃ¡ssica [cite: 82][cite\_start], o projeto explora de forma sistemÃ¡tica diferentes arquiteturas de Circuitos QuÃ¢nticos Variacionais (VQC) para a classificaÃ§Ã£o binÃ¡ria do dataset Iris (Setosa vs. Versicolor)[cite: 5].

[cite\_start]O foco principal Ã© a reprodutibilidade e a anÃ¡lise aprofundada, com geraÃ§Ã£o automÃ¡tica de artefatos [cite: 6, 45][cite\_start], relatÃ³rios e visualizaÃ§Ãµes para cada execuÃ§Ã£o[cite: 131]. [cite\_start]A metodologia inclui estratÃ©gias avanÃ§adas para aumentar a expressividade dos modelos e mitigar desafios comuns em Machine Learning QuÃ¢ntico (MLQ), como o fenÃ´meno dos *barren plateaus*[cite: 6, 11].

-----

## âœ¨ Principais Funcionalidades

  - [cite\_start]**Modelo HÃ­brido QuÃ¢ntico-ClÃ¡ssico:** IntegraÃ§Ã£o robusta entre Cirq e TensorFlow para treinar VQCs[cite: 82, 128].
  - [cite\_start]**ComparaÃ§Ã£o de Arquiteturas de Circuitos:** AvaliaÃ§Ã£o sistemÃ¡tica de topologias de entrelaÃ§amento, incluindo `Linear`, `Alternating` e `Ring`[cite: 19, 22, 24, 430].
  - [cite\_start]**CodificaÃ§Ã£o de Dados AvanÃ§ada (Feature Map):** Utiliza a tÃ©cnica de *re-uploading* de dados com mÃºltiplos conjuntos de constantes de escala (`quantum`, `qinfo`, `math`) para maximizar a expressividade do modelo[cite: 284, 293, 303].
  - [cite\_start]**AnÃ¡lise de *Barren Plateaus*:** Ferramentas para visualizar a paisagem de gradientes e diagnosticar problemas de treinabilidade[cite: 11, 452, 103].
  - [cite\_start]**OtimizaÃ§Ã£o de HiperparÃ¢metros:** Uso de OtimizaÃ§Ã£o Bayesiana para encontrar os melhores hiperparÃ¢metros da parte clÃ¡ssica do modelo[cite: 31, 466].
  - [cite\_start]**Ensemble de Circuitos:** CombinaÃ§Ã£o de mÃºltiplas arquiteturas de VQCs para melhorar a robustez e a acurÃ¡cia das prediÃ§Ãµes[cite: 459, 869, 103].
  - [cite\_start]**Teste de Robustez:** AvaliaÃ§Ã£o da performance do modelo final contra dados com ruÃ­do gaussiano adicionado[cite: 863, 103].
  - [cite\_start]**GeraÃ§Ã£o AutomÃ¡tica de RelatÃ³rios:** CriaÃ§Ã£o de relatÃ³rios detalhados para pÃºblicos distintos (cientÃ­fico e leigo), incluindo matrizes de confusÃ£o, curvas ROC e resumos de performance[cite: 102, 181, 195, 482].
  - [cite\_start]**VisualizaÃ§Ãµes AvanÃ§adas:** GeraÃ§Ã£o de diagramas de circuitos, visualizaÃ§Ã£o de estados na Esfera de Bloch e grÃ¡ficos de alta qualidade para publicaÃ§Ãµes[cite: 34, 35, 389].
  - [cite\_start]**MÃ³dulo de DemonstraÃ§Ã£o de Algoritmos AvanÃ§ados:** ImplementaÃ§Ãµes e resultados para VQE, QAOA, QNN, AQC e QEC, mostrando a versatilidade da plataforma[cite: 668, 871, 104].

-----

## ğŸš€ Resultados de Exemplo (ExecuÃ§Ã£o `20250914_163832`)

Os artefatos fornecidos correspondem a uma execuÃ§Ã£o completa do pipeline. Abaixo estÃ£o os principais resultados consolidados.

#### **ConfiguraÃ§Ã£o do Ambiente**

  - [cite\_start]**Python:** 3.13.3 [cite: 976]
  - [cite\_start]**TensorFlow:** 2.20.0 [cite: 977]
  - [cite\_start]**Cirq:** 1.6.1 [cite: 977]
  - [cite\_start]**Dataset:** Iris (Setosa vs. Versicolor), 70 amostras de treino e 30 de teste[cite: 977].
  - **ConfiguraÃ§Ã£o do VQC:** 4 qubits, 2 camadas, e conjunto de escalas `qinfo`.

#### **Resumo dos Algoritmos AvanÃ§ados Demonstrados**

| Algoritmo | MÃ©trica Principal | Valor Obtido |
| :--- | :--- | :--- |
| **VQE** | `ground_state_energy` | [cite\_start]-0.997575 [cite: 1] |
| **QAOA** | `max_expectation` | [cite\_start]2.511605 [cite: 1] |
| **QNN** | `final_loss` | [cite\_start]0.039483 [cite: 1] |
| **AQC** | `final_overlap` | [cite\_start]1.000000 [cite: 1] |
| **QEC** | `final_fidelity` | [cite\_start]0.975000 [cite: 1] |

#### **Melhores HiperparÃ¢metros Encontrados (OtimizaÃ§Ã£o Bayesiana)**

  - **Learning Rate:** `0.0405`
  - **Hidden Units:** `10`
  - **Dropout Rate:** `0.489`
  - **Num Layers (ClÃ¡ssico):** `3`
  - **Melhor Score (val\_loss):** `0.445`

-----

## ğŸ”§ Como Executar

1.  **Clone o repositÃ³rio:**

    ```bash
    git clone https://github.com/SEU-USUARIO/otimizacao-adaptativa-vqc.git
    cd otimizacao-adaptativa-vqc
    ```

2.  **Crie um ambiente virtual e instale as dependÃªncias:**

    ```bash
    python -m venv venv
    source venv/bin/activate  # No Windows: venv\Scripts\activate
    pip install tensorflow cirq scikit-learn matplotlib seaborn qutip
    ```

    [cite\_start]*As versÃµes utilizadas no projeto foram `tensorflow==2.20.0`, `cirq==1.6.1`, entre outras[cite: 976, 977].*

3.  **Execute o script principal:**

    ```bash
    python QUANTUM
    ```

4.  **Analise os resultados:**
    [cite\_start]Todos os artefatos (dados, figuras, modelos, mÃ©tricas e relatÃ³rios) serÃ£o salvos no diretÃ³rio `output/runs/YYYYMMDD_HHMMSS/`[cite: 45, 136].

-----

## ğŸ”¬ Metodologia

O pipeline segue uma abordagem estruturada:

1.  [cite\_start]**PrÃ©-processamento:** Os dados do dataset Iris sÃ£o filtrados para uma classificaÃ§Ã£o binÃ¡ria, normalizados para o intervalo `[0, 1]` e divididos em conjuntos de treino e teste[cite: 14, 16, 768].
2.  **ConstruÃ§Ã£o do VQC:** O circuito Ã© construÃ­do em Cirq, consistindo em camadas alternadas de:
      - [cite\_start]**CodificaÃ§Ã£o de Dados (Feature Map):** As caracterÃ­sticas clÃ¡ssicas sÃ£o mapeadas em rotaÃ§Ãµes nos qubits[cite: 289, 290].
      - [cite\_start]**Camada Variacional (Ansatz):** RotaÃ§Ãµes parametrizadas (treinÃ¡veis) e portas de entrelaÃ§amento (CNOTs) sÃ£o aplicadas para criar correlaÃ§Ãµes quÃ¢nticas[cite: 334].
3.  **ExtraÃ§Ã£o de Features QuÃ¢nticas:** Para cada amostra de dado, o circuito Ã© simulado e o valor esperado de um observÃ¡vel de Pauli (ex: `Z_k`) Ã© calculado. [cite\_start]Esse valor se torna a "feature quÃ¢ntica"[cite: 9, 28, 778, 781].
4.  [cite\_start]**Treinamento do Modelo ClÃ¡ssico:** As features quÃ¢nticas extraÃ­das sÃ£o usadas para treinar uma rede neural densa em TensorFlow, que realiza a classificaÃ§Ã£o final[cite: 29, 807].

-----

## ğŸ“ˆ PrÃ³ximos Passos Sugeridos

O cÃ³digo jÃ¡ implementa uma vasta gama de tÃ©cnicas, e os prÃ³ximos passos podem incluir:

  - [cite\_start]Avaliar a transpilaÃ§Ã£o do circuito para topologias de hardware quÃ¢ntico real[cite: 106].
  - [cite\_start]Explorar estratÃ©gias de regularizaÃ§Ã£o de custo e inicializaÃ§Ãµes informadas para mitigar *barren plateaus*[cite: 106].
  - [cite\_start]Expandir a aplicaÃ§Ã£o para datasets mais complexos e tarefas de mÃºltiplas classes ou regressÃ£o[cite: 106].
  - [cite\_start]Integrar com hardware quÃ¢ntico real atravÃ©s de plataformas na nuvem[cite: 874].

## ğŸ“š ReferÃªncias

Este trabalho se baseia em conceitos fundamentais da literatura de MLQ:

>   - McClean, J. R., et al. (2018). [cite\_start]*Barren plateaus in quantum neural network training landscapes*[cite: 71, 153].
>   - Cerezo, M., et al. (2021). [cite\_start]*Variational quantum algorithms*[cite: 72, 154].
>   - Schuld, M., et al. (2019). [cite\_start]*Evaluating analytic gradients on quantum hardware for hybrid quantum-classical algorithms*[cite: 73, 155].
>   - PÃ©rez-Salinas, A., et al. (2020). [cite\_start]*Data re-uploading for a universal quantum classifier*[cite: 321].
>   - HavlÃ­Äek, V., et al. (2019). [cite\_start]*Supervised learning with quantum-enhanced feature spaces*[cite: 322].
